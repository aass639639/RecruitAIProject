from typing import List, Optional, Dict
import logging
from core.config import settings
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents import Document
from sqlalchemy.orm import Session
from models.knowledge import Knowledge
from schemas.knowledge import KnowledgeItem, KnowledgeAnswer, KnowledgeItemCreate
from crud.knowledge import get_knowledge_all, create_knowledge
import datetime

from .retriever import create_hybrid_retriever, ArkEmbeddings
from .intent import SimpleIntentRecognizer, QueryCategory
from .rewriter import SimpleQueryRewriter

logger = logging.getLogger(__name__)

# ä¼šè¯å†å²å­˜å‚¨
chat_store: Dict[str, List[Dict]] = {}

class KnowledgeService:
    def __init__(self):
        print("ğŸš€ Initializing KnowledgeService with RAG (LLM: Doubao/Ark)...")
        # åˆå§‹åŒ– LLM (ä½¿ç”¨ Doubao/Ark)
        self.llm = ChatOpenAI(
            model=settings.LLM_MODEL,
            api_key=settings.ARK_API_KEY,
            base_url=settings.ARK_BASE_URL,
            temperature=0.1,
            top_p=0.9,
            max_tokens=1024
        )
        
        # åˆå§‹åŒ– Embedding (ä½¿ç”¨è‡ªå®šä¹‰ ArkEmbeddings)
        self.embeddings = ArkEmbeddings(
            model=settings.EMBEDDING_MODEL,
            api_key=settings.ARK_API_KEY,
            base_url=settings.ARK_BASE_URL
        )
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.intent_recognizer = SimpleIntentRecognizer(self.llm)
        self.query_rewriter = SimpleQueryRewriter(self.llm)
        
        # ç¼“å­˜æ£€ç´¢å™¨
        self.retriever = None
        self.last_doc_count = 0

    def seed_data_if_empty(self, db: Session):
        count = db.query(Knowledge).count()
        if count == 0:
            logger.info("Knowledge base is empty, seeding default data...")
            default_data = [
                {
                    "title": "èµ„æ·±åç«¯å¼€å‘é¢è¯•è€ƒå¯Ÿé‡ç‚¹",
                    "category": "é¢è¯•è¦æ±‚",
                    "content": "1. åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡ï¼šCAPç†è®ºã€Baseç†è®ºã€å¼ºä¸€è‡´æ€§ä¸æœ€ç»ˆä¸€è‡´æ€§çš„æƒè¡¡ã€‚\n2. é«˜å¹¶å‘å¤„ç†ï¼šç¼“å­˜ç©¿é€/å‡»ç©¿/é›ªå´©è§£å†³æ–¹æ¡ˆã€æ¶ˆæ¯é˜Ÿåˆ—å¼‚æ­¥è§£è€¦ã€‚\n3. æ•°æ®åº“ä¼˜åŒ–ï¼šç´¢å¼•åŸç†ã€SQLä¼˜åŒ–ã€åˆ†åº“åˆ†è¡¨ç­–ç•¥ã€‚\n4. æ¶æ„èƒ½åŠ›ï¼šå¾®æœåŠ¡æ²»ç†ã€Service Meshã€é¢†åŸŸé©±åŠ¨è®¾è®¡(DDD)ã€‚",
                    "tags": ["åç«¯", "èµ„æ·±", "ç³»ç»Ÿè®¾è®¡"]
                },
                {
                    "title": "å‰ç«¯æ¶æ„å¸ˆæ ¸å¿ƒèƒ½åŠ›çŸ©é˜µ",
                    "category": "è€ƒå¯Ÿäº‹é¡¹",
                    "content": "1. å·¥ç¨‹åŒ–èƒ½åŠ›ï¼šWebpack/Vite æ„å»ºä¼˜åŒ–ã€Monorepo ç®¡ç†ã€‚\n2. æ€§èƒ½ä¼˜åŒ–ï¼šé¦–å±åŠ è½½ã€æ¸²æŸ“ç“¶é¢ˆåˆ†æã€Core Web Vitalsã€‚\n3. æ¡†æ¶æ·±åº¦ï¼šReact/Vue æ¸²æŸ“æœºåˆ¶ã€çŠ¶æ€ç®¡ç†è®¾è®¡æ¨¡å¼ã€‚\n4. è·¨ç«¯æŠ€æœ¯ï¼šReact Nativeã€Electronã€å°ç¨‹åºæ¶æ„ã€‚",
                    "tags": ["å‰ç«¯", "æ¶æ„å¸ˆ", "å·¥ç¨‹åŒ–"]
                },
                {
                    "title": "è¡Œä¸ºé¢è¯• (STARåŸåˆ™) è¯„ä»·æ ‡å‡†",
                    "category": "é€šç”¨æ ‡å‡†",
                    "content": "S (Situation): äº‹æƒ…å‘ç”Ÿçš„èƒŒæ™¯ã€‚\nT (Task): é¢å¯¹çš„ä»»åŠ¡å’Œç›®æ ‡ã€‚\nA (Action): é’ˆå¯¹ä»»åŠ¡é‡‡å–çš„å…·ä½“è¡ŒåŠ¨ã€‚\nR (Result): æœ€ç»ˆè¾¾æˆçš„ç»“æœã€‚\nè¯„ä»·é‡ç‚¹ï¼šé€»è¾‘æ¸…æ™°åº¦ã€çœŸå®æ€§ã€å€™é€‰äººåœ¨å…¶ä¸­çš„è§’è‰² and è´¡çŒ®ã€‚",
                    "tags": ["è¡Œä¸ºé¢è¯•", "è½¯æŠ€èƒ½", "é€šç”¨"]
                },
                {
                    "title": "Java JVM è°ƒä¼˜ä¸å†…å­˜æ¨¡å‹",
                    "category": "æŠ€æœ¯æ–‡æ¡£",
                    "content": "1. JMM (Java Memory Model)ï¼šä¸»å†…å­˜ä¸å·¥ä½œå†…å­˜ã€åŸå­æ€§ã€å¯è§æ€§ã€æœ‰åºæ€§ã€‚\n2. åƒåœ¾å›æ”¶ç®—æ³•ï¼šG1, ZGC, CMS çš„åŸç†ä¸é€‚ç”¨åœºæ™¯ã€‚\n3. JVM å‚æ•°è°ƒä¼˜ï¼š-Xms, -Xmx, -XX:MaxMetaspaceSize, -XX:+PrintGCDetailsã€‚\n4. å†…å­˜æ³„æ¼æ’æŸ¥ï¼šä½¿ç”¨ jmap, jstack, VisualVM åˆ†æ Heap Dumpã€‚",
                    "tags": ["Java", "JVM", "è°ƒä¼˜"]
                }
            ]
            for item in default_data:
                create_knowledge(db, KnowledgeItemCreate(**item))
            logger.info(f"Seeded {len(default_data)} items.")

    def _get_retriever(self, db: Session):
        all_items = get_knowledge_all(db)
        if not self.retriever or len(all_items) != self.last_doc_count:
            documents = [
                Document(
                    page_content=f"æ ‡é¢˜: {item.title}\nå†…å®¹: {item.content}",
                    metadata={"id": str(item.id), "title": item.title, "category": item.category}
                )
                for item in all_items
            ]
            if documents:
                self.retriever = create_hybrid_retriever(documents, self.embeddings)
                self.last_doc_count = len(all_items)
        return self.retriever

    async def get_all_knowledge(self, db: Session) -> List[KnowledgeItem]:
        self.seed_data_if_empty(db)
        items = get_knowledge_all(db)
        result = []
        for item in items:
            result.append(KnowledgeItem(
                id=str(item.id),
                title=item.title,
                category=item.category,
                content=item.content,
                tags=item.tags,
                updatedAt=item.updated_at.strftime("%Y-%m-%d")
            ))
        return result

    async def chat_with_knowledge(self, db: Session, question: str, session_id: str = "default") -> KnowledgeAnswer:
        self.seed_data_if_empty(db)
        
        # 1. è·å–ä¼šè¯å†å²
        history = chat_store.get(session_id, [])
        
        # 2. æ„å›¾è¯†åˆ«
        intent = self.intent_recognizer.categorize(question, history)
        logger.info(f"User intent: {intent}")
        
        # 3. å¤„ç†é HR é—®é¢˜
        if intent["category"] == "greeting":
            return KnowledgeAnswer(answer="ä½ å¥½ï¼æˆ‘æ˜¯æ‚¨çš„æ™ºèƒ½ HR åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ", source_ids=[])
        elif intent["category"] == "small_talk":
            # ç®€å•çš„é—²èŠå¤„ç†
            response = self.llm.invoke(f"ç”¨æˆ·è¯´: {question}\nè¯·ä½œä¸ºä¸€ä¸ªå‹å¥½çš„ HR åŠ©æ‰‹ç»™å‡ºç®€çŸ­å›åº”ã€‚")
            return KnowledgeAnswer(answer=response.content, source_ids=[])
            
        # 4. æŸ¥è¯¢é‡å†™
        rewritten_query = self.query_rewriter.rewrite(question, history)
        logger.info(f"Rewritten query: {rewritten_query}")
        
        # 5. æ£€ç´¢çŸ¥è¯†
        retriever = self._get_retriever(db)
        final_docs = retriever.invoke(rewritten_query)
        source_ids = [doc.metadata["id"] for doc in final_docs]
            
        # 6. ç”Ÿæˆå›ç­”
        context = "\n\n".join([doc.page_content for doc in final_docs])
        context_text = f"### çŸ¥è¯†åº“å‚è€ƒå†…å®¹ï¼š\n{context}"
        system_message = {"role": "system", "content": f"{settings.HR_SYSTEM_PROMPT}\n\n{context_text}"}
        
        # æ„é€ å®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆåŒ…å«å†å²ï¼‰
        messages = [system_message]
        
        # æ·»åŠ å†å²æ¶ˆæ¯ (è½¬æ¢ role æ ¼å¼)
        for msg in history:
            messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
            
        # æ·»åŠ å½“å‰é—®é¢˜
        messages.append({"role": "user", "content": rewritten_query})
        
        try:
            # æ­£ç¡®è°ƒç”¨ LLM (ä¼ å…¥æ¶ˆæ¯åˆ—è¡¨å¯¹è±¡)
            response = self.llm.invoke(messages)
            answer = response.content
            
            # æ›´æ–°å†å²
            history.append({"role": "user", "content": question})
            history.append({"role": "assistant", "content": answer})
            chat_store[session_id] = history[-10:] # ä¿ç•™æœ€è¿‘10æ¡
            
            return KnowledgeAnswer(answer=answer, source_ids=source_ids)
        except Exception as e:
            logger.error(f"Error in chat_with_knowledge: {str(e)}")
            return KnowledgeAnswer(answer=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚", source_ids=[])

    async def get_ai_tip(self, title: str, content: str) -> str:
        try:
            prompt = f"""
            é’ˆå¯¹ä»¥ä¸‹æ‹›è˜çŸ¥è¯†ç‚¹ï¼Œä¸ºé¢è¯•å®˜æä¾›ä¸€æ¡ç®€çŸ­ã€ä¸“ä¸šçš„é¢è¯•å»ºè®®ã€‚
            çŸ¥è¯†ç‚¹æ ‡é¢˜ï¼š{title}
            çŸ¥è¯†ç‚¹å†…å®¹ï¼š{content}
            """
            response = self.llm.invoke(prompt)
            return response.content
        except Exception as e:
            return f"ç”Ÿæˆæç¤ºå¤±è´¥: {str(e)}"

knowledge_service = KnowledgeService()

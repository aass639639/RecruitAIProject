from typing import List
from langchain_core.documents import Document
from langchain_chroma import Chroma
from langchain_community.retrievers import BM25Retriever
from langchain_classic.retrievers import EnsembleRetriever
from langchain_core.embeddings import Embeddings
import jieba
import os
import shutil
import requests
from core.config import settings

class ArkEmbeddings(Embeddings):
    """è‡ªå®šä¹‰ç«å±±å¼•æ“ Embedding ç±»ï¼Œç¡®ä¿å‘é€åŸå§‹å­—ç¬¦ä¸²"""
    def __init__(self, model: str, api_key: str, base_url: str):
        self.model = model
        self.api_key = api_key
        self.base_url = base_url
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

    def _get_embedding(self, text: str) -> List[float]:
        url = f"{self.base_url}/embeddings"
        # è±†åŒ…/ç«å±±å¼•æ“æ¥å£é€šå¸¸è¦æ±‚ input æ˜¯åˆ—è¡¨
        payload = {
            "model": self.model,
            "input": [text] 
        }
        try:
            resp = requests.post(url, headers=self.headers, json=payload, timeout=10)
            if resp.status_code != 200:
                print(f"âŒ Ark Embedding API æŠ¥é”™: {resp.status_code} - {resp.text}")
                # å¦‚æœæ¨¡å‹åç§°ä¸å¯¹ï¼Œæç¤ºç”¨æˆ·
                if "Endpoint" in resp.text or "not found" in resp.text:
                    print(f"ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿åœ¨ KEY.py æˆ–ç¯å¢ƒå˜é‡ä¸­è®¾ç½®äº†æ­£ç¡®çš„ ARK_EMBEDDING_MODEL (æ¥å…¥ç‚¹ IDï¼Œè€Œéæ¨¡å‹åç§°)")
            resp.raise_for_status()
            data = resp.json()
            return data["data"][0]["embedding"]
        except Exception as e:
            return [0.0] * 1024 # è¿”å›é›¶å‘é‡é˜²æ­¢ç¨‹åºå´©æºƒ

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        return [self._get_embedding(t) for t in texts]

    def embed_query(self, text: str) -> List[float]:
        return self._get_embedding(text)

class ChineseBM25Retriever(BM25Retriever):
    def _tokenize(self, text: str) -> List[str]:
        words = []
        for word in jieba.cut(text):
            word = word.strip()
            if len(word) > 0:
                words.append(word)
        return words

def create_hybrid_retriever(documents: List[Document], embedding_model: Embeddings) -> EnsembleRetriever:
    """åˆ›å»ºæ··åˆæ£€ç´¢å™¨ (Chroma + BM25)"""
    if not documents:
        raise ValueError("æ–‡æ¡£åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºæ£€ç´¢å™¨")

    # 1. åˆ›å»º BM25 æ£€ç´¢å™¨ (ç¨€ç–æ£€ç´¢)
    bm25_retriever = ChineseBM25Retriever.from_documents(documents)
    bm25_retriever.k = settings.SPARSE_K
    
    # 2. åˆ›å»º Chroma å‘é‡æ£€ç´¢å™¨ (ç¨ å¯†æ£€ç´¢)
    try:
        # å¦‚æœå·²å­˜åœ¨æ—§çš„æ•°æ®åº“ç›®å½•ï¼Œå…ˆæ¸…ç†ä»¥ç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼ˆæˆ–è€…ä½ ä¹Ÿå¯ä»¥é€‰æ‹©å¢é‡æ›´æ–°ï¼‰
        # è¿™é‡Œä¸ºäº†æ¼”ç¤ºç®€å•ï¼Œæˆ‘ä»¬æ¯æ¬¡é‡æ–°åˆ›å»º
        if os.path.exists(settings.CHROMA_DB_PATH):
            shutil.rmtree(settings.CHROMA_DB_PATH)
            
        vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=embedding_model,
            persist_directory=settings.CHROMA_DB_PATH,
            collection_name=settings.COLLECTION_NAME
        )
        dense_retriever = vectorstore.as_retriever(search_kwargs={"k": settings.DENSE_K})
        
        # 3. æ··åˆæ£€ç´¢å™¨ (Ensemble)
        ensemble_retriever = EnsembleRetriever(
            retrievers=[bm25_retriever, dense_retriever],
            weights=[0.5, 0.5] # å¯ä»¥æ ¹æ®æ•ˆæœè°ƒæ•´æƒé‡
        )
        print(f"âœ… Chroma å‘é‡åº“å·²å°±ç»ªï¼Œæ··åˆæ£€ç´¢å·²å¯ç”¨ã€‚å­˜å‚¨è·¯å¾„: {settings.CHROMA_DB_PATH}")
        return ensemble_retriever
        
    except Exception as e:
        print(f"âš ï¸  Chroma åˆå§‹åŒ–å¤±è´¥ï¼Œé™çº§ä»…ä½¿ç”¨ BM25 æ£€ç´¢: {e}")
        return bm25_retriever
